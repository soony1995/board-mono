{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nclass MergeDuplicateChunksPlugin {\n  apply(compiler) {\n    compiler.hooks.compilation.tap(\"MergeDuplicateChunksPlugin\", compilation => {\n      compilation.hooks.optimizeChunksBasic.tap(\"MergeDuplicateChunksPlugin\", chunks => {\n        // remember already tested chunks for performance\n        const notDuplicates = new Set();\n\n        // for each chunk\n        for (const chunk of chunks) {\n          // track a Set of all chunk that could be duplicates\n          let possibleDuplicates;\n          for (const module of chunk.modulesIterable) {\n            if (possibleDuplicates === undefined) {\n              // when possibleDuplicates is not yet set,\n              // create a new Set from chunks of the current module\n              // including only chunks with the same number of modules\n              for (const dup of module.chunksIterable) {\n                if (dup !== chunk && chunk.getNumberOfModules() === dup.getNumberOfModules() && !notDuplicates.has(dup)) {\n                  // delay allocating the new Set until here, reduce memory pressure\n                  if (possibleDuplicates === undefined) {\n                    possibleDuplicates = new Set();\n                  }\n                  possibleDuplicates.add(dup);\n                }\n              }\n              // when no chunk is possible we can break here\n              if (possibleDuplicates === undefined) break;\n            } else {\n              // validate existing possible duplicates\n              for (const dup of possibleDuplicates) {\n                // remove possible duplicate when module is not contained\n                if (!dup.containsModule(module)) {\n                  possibleDuplicates.delete(dup);\n                }\n              }\n              // when all chunks has been removed we can break here\n              if (possibleDuplicates.size === 0) break;\n            }\n          }\n\n          // when we found duplicates\n          if (possibleDuplicates !== undefined && possibleDuplicates.size > 0) {\n            for (const otherChunk of possibleDuplicates) {\n              if (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue;\n              // merge them\n              if (chunk.integrate(otherChunk, \"duplicate\")) {\n                chunks.splice(chunks.indexOf(otherChunk), 1);\n              }\n            }\n          }\n\n          // don't check already processed chunks twice\n          notDuplicates.add(chunk);\n        }\n      });\n    });\n  }\n}\nmodule.exports = MergeDuplicateChunksPlugin;","map":{"version":3,"names":["MergeDuplicateChunksPlugin","apply","compiler","hooks","compilation","tap","optimizeChunksBasic","chunks","notDuplicates","Set","chunk","possibleDuplicates","module","modulesIterable","undefined","dup","chunksIterable","getNumberOfModules","has","add","containsModule","delete","size","otherChunk","hasRuntime","integrate","splice","indexOf","exports"],"sources":["/home/soon/bulletin-board/node_modules/webpack/lib/optimize/MergeDuplicateChunksPlugin.js"],"sourcesContent":["/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nclass MergeDuplicateChunksPlugin {\n\tapply(compiler) {\n\t\tcompiler.hooks.compilation.tap(\n\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\tcompilation => {\n\t\t\t\tcompilation.hooks.optimizeChunksBasic.tap(\n\t\t\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\t\t\tchunks => {\n\t\t\t\t\t\t// remember already tested chunks for performance\n\t\t\t\t\t\tconst notDuplicates = new Set();\n\n\t\t\t\t\t\t// for each chunk\n\t\t\t\t\t\tfor (const chunk of chunks) {\n\t\t\t\t\t\t\t// track a Set of all chunk that could be duplicates\n\t\t\t\t\t\t\tlet possibleDuplicates;\n\t\t\t\t\t\t\tfor (const module of chunk.modulesIterable) {\n\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t// when possibleDuplicates is not yet set,\n\t\t\t\t\t\t\t\t\t// create a new Set from chunks of the current module\n\t\t\t\t\t\t\t\t\t// including only chunks with the same number of modules\n\t\t\t\t\t\t\t\t\tfor (const dup of module.chunksIterable) {\n\t\t\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\t\t\tdup !== chunk &&\n\t\t\t\t\t\t\t\t\t\t\tchunk.getNumberOfModules() === dup.getNumberOfModules() &&\n\t\t\t\t\t\t\t\t\t\t\t!notDuplicates.has(dup)\n\t\t\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\t\t\t// delay allocating the new Set until here, reduce memory pressure\n\t\t\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates = new Set();\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.add(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when no chunk is possible we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) break;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t// validate existing possible duplicates\n\t\t\t\t\t\t\t\t\tfor (const dup of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\t\t// remove possible duplicate when module is not contained\n\t\t\t\t\t\t\t\t\t\tif (!dup.containsModule(module)) {\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.delete(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when all chunks has been removed we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates.size === 0) break;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// when we found duplicates\n\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\tpossibleDuplicates !== undefined &&\n\t\t\t\t\t\t\t\tpossibleDuplicates.size > 0\n\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\tfor (const otherChunk of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\tif (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue;\n\t\t\t\t\t\t\t\t\t// merge them\n\t\t\t\t\t\t\t\t\tif (chunk.integrate(otherChunk, \"duplicate\")) {\n\t\t\t\t\t\t\t\t\t\tchunks.splice(chunks.indexOf(otherChunk), 1);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// don't check already processed chunks twice\n\t\t\t\t\t\t\tnotDuplicates.add(chunk);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t}\n\t\t);\n\t}\n}\nmodule.exports = MergeDuplicateChunksPlugin;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA,YAAY;;AAEZ,MAAMA,0BAA0B,CAAC;EAChCC,KAAKA,CAACC,QAAQ,EAAE;IACfA,QAAQ,CAACC,KAAK,CAACC,WAAW,CAACC,GAAG,CAC7B,4BAA4B,EAC5BD,WAAW,IAAI;MACdA,WAAW,CAACD,KAAK,CAACG,mBAAmB,CAACD,GAAG,CACxC,4BAA4B,EAC5BE,MAAM,IAAI;QACT;QACA,MAAMC,aAAa,GAAG,IAAIC,GAAG,CAAC,CAAC;;QAE/B;QACA,KAAK,MAAMC,KAAK,IAAIH,MAAM,EAAE;UAC3B;UACA,IAAII,kBAAkB;UACtB,KAAK,MAAMC,MAAM,IAAIF,KAAK,CAACG,eAAe,EAAE;YAC3C,IAAIF,kBAAkB,KAAKG,SAAS,EAAE;cACrC;cACA;cACA;cACA,KAAK,MAAMC,GAAG,IAAIH,MAAM,CAACI,cAAc,EAAE;gBACxC,IACCD,GAAG,KAAKL,KAAK,IACbA,KAAK,CAACO,kBAAkB,CAAC,CAAC,KAAKF,GAAG,CAACE,kBAAkB,CAAC,CAAC,IACvD,CAACT,aAAa,CAACU,GAAG,CAACH,GAAG,CAAC,EACtB;kBACD;kBACA,IAAIJ,kBAAkB,KAAKG,SAAS,EAAE;oBACrCH,kBAAkB,GAAG,IAAIF,GAAG,CAAC,CAAC;kBAC/B;kBACAE,kBAAkB,CAACQ,GAAG,CAACJ,GAAG,CAAC;gBAC5B;cACD;cACA;cACA,IAAIJ,kBAAkB,KAAKG,SAAS,EAAE;YACvC,CAAC,MAAM;cACN;cACA,KAAK,MAAMC,GAAG,IAAIJ,kBAAkB,EAAE;gBACrC;gBACA,IAAI,CAACI,GAAG,CAACK,cAAc,CAACR,MAAM,CAAC,EAAE;kBAChCD,kBAAkB,CAACU,MAAM,CAACN,GAAG,CAAC;gBAC/B;cACD;cACA;cACA,IAAIJ,kBAAkB,CAACW,IAAI,KAAK,CAAC,EAAE;YACpC;UACD;;UAEA;UACA,IACCX,kBAAkB,KAAKG,SAAS,IAChCH,kBAAkB,CAACW,IAAI,GAAG,CAAC,EAC1B;YACD,KAAK,MAAMC,UAAU,IAAIZ,kBAAkB,EAAE;cAC5C,IAAIY,UAAU,CAACC,UAAU,CAAC,CAAC,KAAKd,KAAK,CAACc,UAAU,CAAC,CAAC,EAAE;cACpD;cACA,IAAId,KAAK,CAACe,SAAS,CAACF,UAAU,EAAE,WAAW,CAAC,EAAE;gBAC7ChB,MAAM,CAACmB,MAAM,CAACnB,MAAM,CAACoB,OAAO,CAACJ,UAAU,CAAC,EAAE,CAAC,CAAC;cAC7C;YACD;UACD;;UAEA;UACAf,aAAa,CAACW,GAAG,CAACT,KAAK,CAAC;QACzB;MACD,CACD,CAAC;IACF,CACD,CAAC;EACF;AACD;AACAE,MAAM,CAACgB,OAAO,GAAG5B,0BAA0B","ignoreList":[]},"metadata":{},"sourceType":"script"}